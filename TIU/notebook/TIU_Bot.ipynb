{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TIU_Bot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTx1jfdAJOax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d4f701f-62ba-4561-f735-7dd14ee39c0f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqcFYT2PVJhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "308ede3e-1075-40fa-bedb-1d6c48138642"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 以下の記号はスペースに置き換えます（カンマ、ピリオドを除く）。\n",
        "# punctuationとは日本語で句点という意味です\n",
        "print(\"区切り文字：\", string.punctuation)\n",
        "# !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "# 前処理\n",
        "def preprocessing_text(text):\n",
        "  # 改行コードを消去\n",
        "  text = re.sub('<br />', '', text)\n",
        "  # カンマ、ピリオド以外の記号をスペースに置換\n",
        "  for p in string.punctuation:\n",
        "    if (p == \".\") or (p == \",\"):\n",
        "      continue\n",
        "    else:\n",
        "      text = text.replace(p, \" \")\n",
        "  # ピリオドなどの前後にはスペースを入れておく\n",
        "  text = text.replace(\".\", \" . \")\n",
        "  text = text.replace(\",\", \" , \")\n",
        "  return text\n",
        "\n",
        "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
        "def tokenizer_punctuation(text):\n",
        "  return text.strip().split()\n",
        "\n",
        "# 前処理と分かち書きをまとめた関数を定義\n",
        "def tokenizer_with_preprocessing(text):\n",
        "  text = preprocessing_text(text)\n",
        "  ret = tokenizer_punctuation(text)\n",
        "  return ret\n",
        "\n",
        "\n",
        "# 動作を確認します\n",
        "print(tokenizer_with_preprocessing('I like cats+'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "区切り文字： !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['I', 'like', 'cats']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-qrP4OVTFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "MAX_LENGTH = 30\n",
        "\n",
        "#テキストに処理を行うFieldを定義\n",
        "#fix_lengthはtokenの数\n",
        "SRC = torchtext.data.Field(sequential=True, use_vocab=True, tokenize=tokenizer_with_preprocessing,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=MAX_LENGTH)\n",
        "\n",
        "TRG = torchtext.data.Field(sequential=True, use_vocab=True, tokenize=tokenizer_with_preprocessing,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=MAX_LENGTH,\n",
        "                            init_token='<cls>', eos_token='<eos>')\n",
        "\n",
        "#pandasでcsvを保存するときに、labelをintでキャストしておかないとエラーでるから注意\n",
        "train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='/content/drive/My Drive/dataset/TIU/MovieAndDaily', train='tiu_train.csv', validation='_validation.csv', \n",
        "    test='_test.csv', format='csv', fields=[('src', SRC), ('trg', TRG)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcVN2LSfVYyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61515004-d9eb-40bc-a555-b24503f1a238"
      },
      "source": [
        "SRC.build_vocab(train_ds)\n",
        "TRG.build_vocab(train_ds)\n",
        "print(len(SRC.vocab.stoi))\n",
        "print(len(TRG.vocab.stoi))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20363\n",
            "20227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPiPSUJ-WIaG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7dfdd71-633f-4f05-984c-7ddd614ab1c9"
      },
      "source": [
        "from torchtext import data\n",
        "\n",
        "train_dl = data.Iterator(train_ds, batch_size=64, train=True)\n",
        "val_dl = data.Iterator(val_ds, batch_size=64, train=False, sort=False)\n",
        "batch = next(iter(val_dl))\n",
        "print(batch.src[0].shape)\n",
        "print(batch.trg[0].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 30])\n",
            "torch.Size([64, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNpekymSWQlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, vocab_size, dropout=0):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "    self.thought = nn.Linear(hidden_size*2, hidden_size)\n",
        "\n",
        "\n",
        "  def forward(self, input_seq, hidden=None):\n",
        "    embedded = self.embedding(input_seq) #[64, 30, 600]\n",
        "    outputs, (hn, cn) = self.lstm(embedded) #[64, 30, 1200], ([2, 64, 600], [2, 64, 600])\n",
        "    outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] #[64, 30, 600]\n",
        "    thought_vector = torch.cat((hn[0], hn[1]), -1) #[64, 1200]\n",
        "    thought_vector = self.thought(thought_vector).unsqueeze(0) #[1, 64, 600]\n",
        "\n",
        "    return outputs, thought_vector"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er_R9bzRWW8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, dropout=0.1):\n",
        "    super(LuongAttnDecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.embedding_dropout = nn.Dropout(dropout)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "    self.score = nn.Linear(hidden_size, hidden_size)\n",
        "    self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "  def forward(self, input_step, decoder_hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input_step)\n",
        "    embedded = self.embedding_dropout(embedded)\n",
        "    embedded = embedded.unsqueeze(1) #[64, 1, 600]\n",
        "    \n",
        "    #記憶セルはencoderから引っ張ってこない\n",
        "    rnn_output, hidden = self.lstm(embedded, decoder_hidden) #[64, 1, 600] ([1, 64, 600], [1, 64, 600])\n",
        "    energy = self.score(encoder_outputs) # [64, 30, 600]\n",
        "    attn_weights = torch.sum(rnn_output*energy, dim=2) #[64, 30]\n",
        "    attn_weights = F.softmax(attn_weights, dim=1).unsqueeze(1) # [64, 1, 30]\n",
        "\n",
        "    context = attn_weights.bmm(encoder_outputs) #[64, 1, 500]\n",
        "    rnn_output = rnn_output.squeeze(1) #[64, 500]\n",
        "    context = context.squeeze(1) #[64, 500]\n",
        "    concat_input = torch.cat((rnn_output, context), 1) #[64, 1000]\n",
        "    concat_output = torch.tanh(self.concat(concat_input))\n",
        "    output = self.out(concat_output)\n",
        "    output = F.softmax(output, dim=1)\n",
        "\n",
        "    return output, hidden"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHrgZk7xWcUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binaryMatrix(l, value=TRG.vocab.stoi['<pad>']):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "      if seq == TRG.vocab.stoi['<pad>']:\n",
        "        m.append(False)\n",
        "      else:\n",
        "        m.append(True)\n",
        "    return m\n",
        "\n",
        "def maskNLLLoss(inp, target):\n",
        "    mask = target\n",
        "    mask = binaryMatrix(mask)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    mask = mask.to(device)\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6FVJobHWeh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def a_batch_loss(input_variable, target_variable, max_target_len, encoder, decoder, \n",
        "                 encoder_optimizer, decoder_optimizer, phase):\n",
        "  total_loss = 0 #1batchのloss\n",
        "  # Zero gradients\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  n_totals = 0\n",
        "  print_losses = []\n",
        "  \n",
        "  #エンコーダの出力\n",
        "  encoder_outputs, thought_vector = encoder(input_variable)\n",
        "  #['<cls>']を生成\n",
        "  decoder_input = torch.LongTensor([TRG.vocab.stoi['<cls>'] for _ in range(batch_size)]) #[64]\n",
        "  decoder_input = decoder_input.to(device)\n",
        "  #エンコーダの最後の隠れ状態を使用、記憶セルは0を入力\n",
        "  cn = torch.zeros(1, batch_size, hidden_size, device=device)\n",
        "  decoder_hidden = (thought_vector, cn)\n",
        "\n",
        "  #teaching_forceを使う\n",
        "  loss = 0 #1batchの中の1センテンスのloss\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    for t in range(max_target_len):\n",
        "      decoder_output, decoder_hidden = decoder(\n",
        "          decoder_input, decoder_hidden, encoder_outputs\n",
        "      ) #[64, 単語種類数], [2, 64, 500]\n",
        "      # Teacher forcing: next input is current target\n",
        "      decoder_input = target_variable[:, t] #[64], teaching_forceの場合、正解データを次に入力する\n",
        "      #loss += criterion(decoder_output, target_variable[:, t])\n",
        "      mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[:, t])\n",
        "      loss += mask_loss\n",
        "      print_losses.append(mask_loss.item() * nTotal)\n",
        "      n_totals += nTotal\n",
        "    #total_loss += loss / max_target_len #1バッチ分のloss\n",
        "    \n",
        "  else:\n",
        "    for t in range(max_target_len):\n",
        "      decoder_output, decoder_hidden = decoder(\n",
        "          decoder_input, decoder_hidden, encoder_outputs\n",
        "      ) #[64, 単語種類数], [2, 64, 500]\n",
        "      # Teacher forcing: next input is current target\n",
        "      _, topi = decoder_output.topk(1)\n",
        "      decoder_input = torch.LongTensor([topi[i] for i in range(batch_size)])\n",
        "      decoder_input = decoder_input.to(device)\n",
        "      #loss += criterion(decoder_output, target_variable[:, t])\n",
        "      mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[:, t])\n",
        "      loss += mask_loss\n",
        "      print_losses.append(mask_loss.item() * nTotal)\n",
        "      n_totals += nTotal\n",
        "    #total_loss += (loss / max_target_len) #1バッチ分のloss\n",
        "    \n",
        "  if phase == 'train':\n",
        "    loss.backward()\n",
        "    #total_loss.backward()\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "  return sum(print_losses) / n_totals\n",
        "  #return total_loss #1バッチ分のloss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saJFzQofWikL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def train_model(dataloaders_dict, num_epochs, encoder, decoder, encoder_optimizer, decoder_optimizer):\n",
        "    print(\"Training...\")\n",
        "    #エポック\n",
        "    for epoch in range(num_epochs):\n",
        "      for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "          encoder.train()\n",
        "          decoder.train()\n",
        "        else:\n",
        "          encoder.eval()\n",
        "          decoder.eval()\n",
        "        print_loss = 0 #1epochのloss\n",
        "\n",
        "        for i, batch in enumerate(dataloaders_dict[phase]): \n",
        "          input_variable = batch.src[0].to(device) #(64, 30)\n",
        "          target_variable = batch.trg[0].to(device) #(64, 30)\n",
        "          max_target_len = max(batch.trg[1])\n",
        "          if target_variable.shape[0] == 64:\n",
        "            total_loss = a_batch_loss(input_variable, target_variable, max_target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, phase) #1バッチ分のloss     \n",
        "            print_loss += total_loss #1epochのlossをprint_lossに加えていく\n",
        "\n",
        "        #損失をだす\n",
        "        print(\"epoch: {}; phase: {}; Average loss: {:.4f}; PPL: {:.4f}\".format(epoch+1, phase, print_loss/i, math.exp(print_loss/i) ))  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIz2LIeDWkhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 600\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "encoder = EncoderRNN(hidden_size, len(SRC.vocab.stoi), dropout)\n",
        "decoder = LuongAttnDecoderRNN(hidden_size, len(TRG.vocab.stoi),  dropout)\n",
        "\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ4qN_n1Wma0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fdebc2df-d93e-430a-f380-039d30a477e5"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "clip = 1.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "num_epochs = 5\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n",
        "\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "encoder.train()\n",
        "decoder.train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LuongAttnDecoderRNN(\n",
              "  (embedding): Embedding(20231, 600)\n",
              "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lstm): LSTM(600, 600, batch_first=True)\n",
              "  (score): Linear(in_features=600, out_features=600, bias=True)\n",
              "  (concat): Linear(in_features=1200, out_features=600, bias=True)\n",
              "  (out): Linear(in_features=600, out_features=20231, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo0XdNgwWrP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ef7472ed-9b20-444a-a73c-350da92dad4d"
      },
      "source": [
        "train_model(dataloaders_dict, num_epochs, encoder, decoder, encoder_optimizer, decoder_optimizer)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "epoch: 1; phase: train; Average loss: 4.1368; PPL: 62.6044\n",
            "epoch: 1; phase: val; Average loss: 3.7362; PPL: 41.9370\n",
            "epoch: 2; phase: train; Average loss: 3.6875; PPL: 39.9463\n",
            "epoch: 2; phase: val; Average loss: 3.5462; PPL: 34.6819\n",
            "epoch: 3; phase: train; Average loss: 3.5015; PPL: 33.1648\n",
            "epoch: 3; phase: val; Average loss: 3.4597; PPL: 31.8078\n",
            "epoch: 4; phase: train; Average loss: 3.3520; PPL: 28.5597\n",
            "epoch: 4; phase: val; Average loss: 3.4000; PPL: 29.9643\n",
            "epoch: 5; phase: train; Average loss: 3.2179; PPL: 24.9765\n",
            "epoch: 5; phase: val; Average loss: 3.3644; PPL: 28.9164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN0yWWU4W2hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(GreedySearchDecoder, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, input_seq, input_length, max_length):\n",
        "    encoder_outputs, thought_vector = self.encoder(input_seq)\n",
        "    cn = torch.zeros(1, 1, hidden_size).to(device)\n",
        "    decoder_hidden = (thought_vector, cn)\n",
        "    decoder_input = torch.LongTensor([TRG.vocab.stoi['<cls>']]).to(device)\n",
        "    all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "    all_scores = torch.zeros([0], device=device)\n",
        "    for _ in range(max_length):\n",
        "      decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "      all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "      all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            #decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "            \n",
        "    return all_tokens, all_scores"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHqx92JFhj14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def indexesFromSentence(sentence):\n",
        "  return [SRC.vocab.stoi[word] if word in SRC.vocab.stoi else SRC.vocab.stoi['<unk>'] for word in sentence.split(' ')]\n",
        "    \n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "  return s\n",
        "\n",
        "def evaluate(encoder, decoder, searcher, sentence, max_length=MAX_LENGTH):\n",
        "  indexes_batch = indexesFromSentence(sentence)\n",
        "  lengths = len(indexes_batch)\n",
        "  input_batch = torch.LongTensor(indexes_batch).view(1, -1).to(device)\n",
        "  tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "  decoded_words = [TRG.vocab.itos[token.item()] for token in tokens]\n",
        "  return decoded_words\n",
        "\n",
        "\n",
        "def evaluateInput(encoder, decoder, searcher):\n",
        "  input_sentence = ''\n",
        "  while(1):\n",
        "    try:\n",
        "      input_sentence = input('> ').lower()\n",
        "      if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "      #ノイズ処理\n",
        "      input_sentence = normalizeString(input_sentence)\n",
        "      output_words = evaluate(encoder, decoder, searcher, input_sentence)\n",
        "      output_words[:] = [x for x in output_words if not (x == '<eos>' or x == '<pad>')]\n",
        "      print('Bot:', ' '.join(output_words))\n",
        "\n",
        "    except KeyError:\n",
        "      print(\"Error: Encountered unknown word.\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlni4H_Yh7Qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d1cacc29-ae1d-4b06-b322-ba4b7b1bf0f6"
      },
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "evaluateInput(encoder, decoder, searcher)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> hello\n",
            "Bot: <cls> yes , i think so . to chicago on nov . , i ’ m afraid i ’ m feeling a bit nervous . snakes is\n",
            ">  I’m worried about something.\n",
            "Bot: <cls> do you know what i m doing . s got to know what s going on . . . .\n",
            "> Well, I have to drive to school for a meeting this morning, and I’m going to end up getting stuck in rush-hour traffic.\n",
            "Bot: <cls> you re right . you re right . . . . . . . . . . . . . .\n",
            "> Is there anything else bothering you?\n",
            "Bot: <cls> yes , i think . . . , i ’ m afraid i can t . , i ’ m afraid . , i ’ m\n",
            "> q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbkEXOKYh8C_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "model_path = '/content/drive/My Drive/dataset/TIU/MovieAndDaily/tiu_encoder0726.pth'\n",
        "torch.save(encoder.to('cpu').state_dict(), model_path)\n",
        "model_path = '/content/drive/My Drive/dataset/TIU/MovieAndDaily/tiu_decoder0726.pth'\n",
        "torch.save(decoder.to('cpu').state_dict(), model_path)\n",
        "\n",
        "model_path = '/content/drive/My Drive/dataset/TIU/MovieAndDaily/cuda_tiu_encoder0726.pth'\n",
        "torch.save(encoder.to('cuda').state_dict(), model_path)\n",
        "model_path = '/content/drive/My Drive/dataset/TIU/MovieAndDaily/cuda_tiu_decoder0726.pth'\n",
        "torch.save(decoder.to('cuda').state_dict(), model_path)\n",
        "\n",
        "with open('/content/drive/My Drive/dataset/TIU/MovieAndDaily/voc_word2index0726.pkl', 'wb') as f:\n",
        "    pickle.dump(SRC.vocab.stoi, f)\n",
        "with open('/content/drive/My Drive/dataset/TIU/MovieAndDaily/voc_index2word0726.pkl', 'wb') as f:\n",
        "    pickle.dump(TRG.vocab.itos, f)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbOJ7_5Hj433",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}