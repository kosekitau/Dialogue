{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TIU_Bi_2layer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm7Lo__78SRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85321aea-2cd5-4fc0-debc-6eb86e4e5ea1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O17e5NQm83EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, emb_size, hidden_size, num_layers, bidirectional, vocab_size, text_embedding_vectors, dropout=0):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.bidirectional = bidirectional\n",
        "    if text_embedding_vectors == None:\n",
        "      self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "    else:\n",
        "      self.embedding = nn.Embedding.from_pretrained(\n",
        "          embeddings=text_embedding_vectors, freeze=True)\n",
        "    self.lstm = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "    self.thought = nn.Linear(hidden_size*2, hidden_size)\n",
        "\n",
        "\n",
        "  def forward(self, input_seq, hidden=None):\n",
        "    embedded = self.embedding(input_seq) #[batch, max_length, emb_size]\n",
        "    outputs, (hn, cn) = self.lstm(embedded) #[batch, max_length, hidden*2], ([2, 64, 600], [2, 64, 600])\n",
        "    outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:] #[batch, max_length, hidden]\n",
        "\n",
        "    encoder_hidden = tuple([hn[i, :, :] + hn[i+1, :, :] for i in range(0, self.num_layers+2*self.bidirectional, 2)])\n",
        "    encoder_hidden = torch.stack(encoder_hidden, 0)\n",
        "\n",
        "    return outputs, encoder_hidden"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp-EPyoEJqIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = EncoderRNN(300, 600, 2, True, 2000, None, dropout=0)\n",
        "outputs, encoder_hidden = en(torch.randint(0, 1000, size=(128, 20)))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB4CKwHeJW2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, emb_size, hidden_size, num_layers, text_embedding_vectors, output_size, dropout=0.1):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dropout = dropout\n",
        "    if text_embedding_vectors == None:\n",
        "      self.embedding = nn.Embedding(output_size, emb_size)\n",
        "    else:\n",
        "      self.embedding = nn.Embedding.from_pretrained(\n",
        "          embeddings=text_embedding_vectors, freeze=True)\n",
        "    self.embedding_dropout = nn.Dropout(dropout)\n",
        "    self.lstm = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "  def forward(self, input_step, decoder_hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input_step)\n",
        "    embedded = self.embedding_dropout(embedded)\n",
        "    embedded = embedded.unsqueeze(1) #[batch, 1, hidden]\n",
        "    print(embedded.shape)\n",
        "    \n",
        "    #記憶セルはencoderから引っ張ってこない\n",
        "    rnn_output, hidden = self.lstm(embedded, decoder_hidden) #[128, 1, 600] ([1, batch, hidden], [1, batch, hidden])\n",
        "    attn_weights = torch.matmul(rnn_output, encoder_outputs.transpose(2, 1))\n",
        "    attn_weights = F.softmax(attn_weights, -1)\n",
        "    attn_applied = torch.bmm(attn_weights, encoder_outputs) # [1,1,256]\n",
        "    output = rnn_output + attn_applied\n",
        "    output = output.squeeze(1)\n",
        "    print(output.shape)\n",
        "    output = self.out(output)\n",
        "    output = F.softmax(output, dim=1)\n",
        "    print(output.shape)\n",
        "\n",
        "    return output, hidden"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-3VWRklyr2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f1c04748-e0ea-4b36-a77f-b9354782ec51"
      },
      "source": [
        "en = EncoderRNN(300, 600, 2, True, 2000, None, dropout=0)\n",
        "de = DecoderRNN(300, 600, 2, None, 1000)\n",
        "outputs, encoder_hidden = en(torch.randint(0, 1000, size=(128, 20)))\n",
        "print(outputs.shape)\n",
        "cn = torch.zeros(2, 128, 600)\n",
        "decoder_hidden = (encoder_hidden, cn)\n",
        "\n",
        "outputs, hidden = de(torch.randint(0, 1000, size=(128,)), decoder_hidden, outputs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 20, 600])\n",
            "torch.Size([128, 1, 300])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY78_e0RzREZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03be2ec3-6bfd-4397-b041-8768a08f4b82"
      },
      "source": [
        "print(outputs.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 600])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNjcYp0T1uJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}